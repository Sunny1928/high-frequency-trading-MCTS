{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score \n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score \n",
    "import optuna\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 估計值\n",
    "def Score(m, x_train, y_train, x_test, y_test, train=True):\n",
    "    # training 的\n",
    "    if train:\n",
    "        pred=m.predict(x_train)\n",
    "        print('Train Result:\\n')\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"Precision Score: {precision_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"Recall Score: {recall_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"F1 score: {f1_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"Confusion Matrix:\\n {confusion_matrix(y_train, pred)}\")\n",
    "    # testing 的\n",
    "    elif train == False:\n",
    "        pred=m.predict(x_test)\n",
    "        print('Test Result:\\n')\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"Precision Score: {precision_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"Recall Score: {recall_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"F1 score: {f1_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, pred)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527175, 12)\n"
     ]
    }
   ],
   "source": [
    "# 讀data\n",
    "state = \"ask\"\n",
    "FILE_PATH = rf\"C:\\Users\\yicheng\\Desktop\\high-frequency-trading-MCTS\\stock_dataset_with_label\\2330\\{state}\\*\"\n",
    "\n",
    "\n",
    "files = glob.glob(FILE_PATH)\n",
    "data=[]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    d = pd.read_csv(f, index_col=None)\n",
    "    d = d.drop(columns=[\"matchPri\",'bidPri1','bidPri2','bidPri3','bidPri4','bidPri5','askPri1','askPri2','askPri3','askPri4','askPri5',\"openPri\"])\n",
    "    data = pd.concat([data,d]) \n",
    "    \n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation  \n",
    "# we split data to 10 parts\n",
    "# TV1 means split data to training 1 part ,validation 9 parts\n",
    "TV = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the length of total data \n",
    "length = len(data)\n",
    "# the length of training data \n",
    "train_length = int(length * TV *0.1)\n",
    "# split training data\n",
    "train_data = data[:train_length]\n",
    "# train input data \n",
    "X_train = train_data.drop(columns=['label'])\n",
    "# train label \n",
    "y_train = train_data['label'].to_numpy()\n",
    "\n",
    "# split testing data\n",
    "test_data = data[train_length:]\n",
    "# tets input data \n",
    "X_test = test_data.drop(columns=['label'])\n",
    "# test label\n",
    "y_test = test_data['label'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徵重要程度:  [0.09583836 0.07846119 0.08632863 0.09179962 0.0960384  0.09726837\n",
      " 0.07891914 0.08856925 0.09223704 0.09600724 0.09853285]\n"
     ]
    }
   ],
   "source": [
    "print('特徵重要程度: ',model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 52717 52717\n",
      "Test  : 474458 474458\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train : {len(X_train)} {len(y_train)}\")\n",
    "print(f\"Test  : {len(X_test)} {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8397 44320\n",
      "change: 15.928448%\n",
      "other : 84.071552%\n"
     ]
    }
   ],
   "source": [
    "# 計算training 的 label 比例分配\n",
    "change = 0\n",
    "other = 0\n",
    "for i in y_train:\n",
    "    \n",
    "    if i == 0:\n",
    "        other+=1\n",
    "    else:\n",
    "        change+=1\n",
    "\n",
    "print(change,other)\n",
    "print('change: {:%}'.format(change/(change+other)))\n",
    "print('other : {:%}'.format(other/(change+other)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_recall = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run weight \n",
    "def Objective(trial):\n",
    "\n",
    "    global best_recall\n",
    "    # 配置要選的權重和range\n",
    "    # 'scale_pos_weight':other/down,這個一定要加 ，他是處理imbalance的 \n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0,log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50,500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0,log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0,log=True),\n",
    "        'scale_pos_weight':other/change,\n",
    "        'reg_alpha':  trial.suggest_float('reg_lambda', 1e-8, 1.0,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0,log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 20),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.01, 1.0),\n",
    "        # CPU thread \n",
    "        'nthread':16\n",
    "    }\n",
    "\n",
    "    # 訓練\n",
    "    model = xgb.XGBClassifier(**param)  \n",
    "    \n",
    "    model.fit(X_train, y_train,verbose=False)\n",
    "    # 預測\n",
    "    X_pred = model.predict(X_train)\n",
    "    # 評估分數\n",
    "    recall = round(f1_score(y_train, X_pred),2)\n",
    "    if recall > best_recall:\n",
    "        # 存model weight\n",
    "        model.save_model(f'xgb_best_{state}{recall}.model')\n",
    "\n",
    "        if os.path.isfile(f'./xgb_best_{state}{best_recall}.model'):\n",
    "            os.remove(f'./xgb_best_{state}{best_recall}.model')\n",
    "        \n",
    "        best_recall = recall\n",
    "        \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-20 23:49:51,545]\u001b[0m A new study created in memory with name: no-name-825e73df-c123-4c0d-91df-d84c5f13742e\u001b[0m\n",
      "c:\\Users\\yicheng\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\optuna\\progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f2c71ea459481dba11b77e4e7f8158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-20 23:49:54,086]\u001b[0m Trial 0 finished with value: 0.48 and parameters: {'max_depth': 11, 'subsample': 0.4707688609026088, 'n_estimators': 140, 'learning_rate': 0.09143993852417222, 'gamma': 1.2514208815765042e-06, 'reg_lambda': 4.625787676464828e-08, 'min_child_weight': 8, 'colsample_bytree': 0.42050494615712947}. Best is trial 0 with value: 0.48.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:01,525]\u001b[0m Trial 1 finished with value: 0.57 and parameters: {'max_depth': 10, 'subsample': 0.7350646968808751, 'n_estimators': 411, 'learning_rate': 0.10100765615720714, 'gamma': 0.00021075357935703697, 'reg_lambda': 0.009050017965259411, 'min_child_weight': 17, 'colsample_bytree': 0.8421060575085494}. Best is trial 1 with value: 0.57.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:02,509]\u001b[0m Trial 2 finished with value: 0.29 and parameters: {'max_depth': 7, 'subsample': 0.022541702615069808, 'n_estimators': 100, 'learning_rate': 0.18485925899363448, 'gamma': 1.1808883534452803e-07, 'reg_lambda': 9.402829472295817e-08, 'min_child_weight': 8, 'colsample_bytree': 0.6883815292471981}. Best is trial 1 with value: 0.57.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:05,620]\u001b[0m Trial 3 finished with value: 0.28 and parameters: {'max_depth': 11, 'subsample': 0.01415990791756483, 'n_estimators': 339, 'learning_rate': 0.034693602201365845, 'gamma': 0.04470322147578083, 'reg_lambda': 0.04700442339211029, 'min_child_weight': 10, 'colsample_bytree': 0.09651205322946745}. Best is trial 1 with value: 0.57.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:07,643]\u001b[0m Trial 4 finished with value: 0.43 and parameters: {'max_depth': 6, 'subsample': 0.7870149202101244, 'n_estimators': 189, 'learning_rate': 0.15203106742385344, 'gamma': 0.19401698332007805, 'reg_lambda': 0.00022841465491048516, 'min_child_weight': 8, 'colsample_bytree': 0.8244589240738263}. Best is trial 1 with value: 0.57.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:11,649]\u001b[0m Trial 5 finished with value: 0.41 and parameters: {'max_depth': 10, 'subsample': 0.11433912176021686, 'n_estimators': 320, 'learning_rate': 0.028448442931379398, 'gamma': 1.4180777409738642e-06, 'reg_lambda': 3.848796731799502e-06, 'min_child_weight': 3, 'colsample_bytree': 0.43285911344848527}. Best is trial 1 with value: 0.57.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:16,162]\u001b[0m Trial 6 finished with value: 0.76 and parameters: {'max_depth': 15, 'subsample': 0.6563881849944677, 'n_estimators': 163, 'learning_rate': 0.1570500000166422, 'gamma': 1.0676114091532102e-08, 'reg_lambda': 0.0929132902748759, 'min_child_weight': 4, 'colsample_bytree': 0.666550060178037}. Best is trial 6 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:20,188]\u001b[0m Trial 7 finished with value: 0.33 and parameters: {'max_depth': 12, 'subsample': 0.03065886346002845, 'n_estimators': 356, 'learning_rate': 0.032271992004769864, 'gamma': 0.13808514099713487, 'reg_lambda': 5.672766724796864e-06, 'min_child_weight': 9, 'colsample_bytree': 0.283284467003589}. Best is trial 6 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:23,420]\u001b[0m Trial 8 finished with value: 0.42 and parameters: {'max_depth': 15, 'subsample': 0.1247380777454554, 'n_estimators': 195, 'learning_rate': 0.1391273216348385, 'gamma': 2.4681430017740857e-07, 'reg_lambda': 1.5459533268016793e-08, 'min_child_weight': 19, 'colsample_bytree': 0.7541064488928679}. Best is trial 6 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 23:50:24,725]\u001b[0m Trial 9 finished with value: 0.32 and parameters: {'max_depth': 7, 'subsample': 0.08920743164245555, 'n_estimators': 130, 'learning_rate': 0.46404489078420236, 'gamma': 3.7010392317717923e-07, 'reg_lambda': 2.8539089300344873e-08, 'min_child_weight': 4, 'colsample_bytree': 0.7104717602719112}. Best is trial 6 with value: 0.76.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 找參數的套件 ㄝㄝ, 很佔資源\n",
    "# direction =\"maximize\" ,代表作為評估的值要找最大值\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# pre-train 用\n",
    "# study.enqueue_trial(study.best_trial)\n",
    "\n",
    "# n_trials 要跑幾次\n",
    "study.optimize(Objective, n_trials = 10,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial:\n",
      "  Value: 0.76\n",
      "  Params: \n",
      "    max_depth: 15\n",
      "    subsample: 0.6563881849944677\n",
      "    n_estimators: 163\n",
      "    learning_rate: 0.1570500000166422\n",
      "    gamma: 1.0676114091532102e-08\n",
      "    reg_lambda: 0.0929132902748759\n",
      "    min_child_weight: 4\n",
      "    colsample_bytree: 0.666550060178037\n"
     ]
    }
   ],
   "source": [
    "# 輸出找到的最佳參數\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yicheng\\Desktop\\high-frequency-trading-MCTS\\model\\xgb_best_ask0.76.model\n",
      "Train Result:\n",
      "\n",
      "Accuracy Score: 90.25%\n",
      "Precision Score: 62.18%\n",
      "Recall Score: 99.00%\n",
      "F1 score: 76.38%\n",
      "Confusion Matrix:\n",
      " [[39263  5057]\n",
      " [   84  8313]]\n",
      "Test Result:\n",
      "\n",
      "Accuracy Score: 75.18%\n",
      "Precision Score: 17.98%\n",
      "Recall Score: 12.97%\n",
      "F1 score: 15.07%\n",
      "Confusion Matrix:\n",
      " [[346274  47661]\n",
      " [ 70078  10445]]\n",
      "特徵重要程度:  [0.10473517 0.08821649 0.08229707 0.09298414 0.09291208 0.08847114\n",
      " 0.08723172 0.08552441 0.08176731 0.0955264  0.10033416]\n"
     ]
    }
   ],
   "source": [
    "# 看一下效果\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# 放best model\n",
    "model_path = rf'C:\\Users\\yicheng\\Desktop\\high-frequency-trading-MCTS\\model\\xgb_best_ask0.76.model'\n",
    "\n",
    "model.load_model(model_path)\n",
    "# training eval\n",
    "Score(model,X_train, y_train, X_test,y_test)\n",
    "# testing eval\n",
    "Score(model,X_train, y_train, X_test,y_test,train=False)\n",
    "\n",
    "print('特徵重要程度: ',model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "\n",
      "Accuracy Score: 99.25%\n",
      "Precision Score: 95.52%\n",
      "Recall Score: 100.00%\n",
      "F1 score: 97.71%\n",
      "Confusion Matrix:\n",
      " [[43926   394]\n",
      " [    0  8397]]\n",
      "Test Result:\n",
      "\n",
      "Accuracy Score: 78.26%\n",
      "Precision Score: 17.63%\n",
      "Recall Score: 7.65%\n",
      "F1 score: 10.67%\n",
      "Confusion Matrix:\n",
      " [[365139  28796]\n",
      " [ 74360   6163]]\n"
     ]
    }
   ],
   "source": [
    "# 這邊就不斷調要train 幾次 ,看recall score \n",
    "# **trial.params : 前面找出來的參數\n",
    "xgb_model = xgb.XGBClassifier(**trial.params)\n",
    "\n",
    "# pre train 的次數\n",
    "num =10 \n",
    "\n",
    "# model_path = f'.\\model\\xgb_best_{state}{round(trial,2)}.model'\n",
    "for i in range(num):\n",
    "    # xgb_model 讀檔的\n",
    "    xgb_model.fit(X_train, y_train,verbose=1,xgb_model=model_path)\n",
    "    # 存檔\n",
    "    xgb_model.save_model(model_path)\n",
    "\n",
    "\n",
    "Score(xgb_model,X_train, y_train, X_test,y_test)\n",
    "Score(xgb_model,X_train, y_train, X_test,y_test,train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
